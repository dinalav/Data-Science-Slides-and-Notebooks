{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tutorial 2.2. Introduction to Google Cloud Platform and Big Query\n",
    "\n",
    "by Nadzeya Laurentsyeva @ nadzeya.laurentsyeva@econ.lmu.de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Motivation for learning about Google Cloud and Big Query\n",
    "* Great computational capacities!\n",
    "* Publicly available big datasets https://cloud.google.com/bigquery/public-data/\n",
    "* Many additional apps for data analysis \n",
    "\n",
    "!But the service is not absolutely free. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Covered in this lecture \n",
    "**Tools** \n",
    "* Google Cloud Platform/Big Query Dashboard\n",
    "* Python client for Google Cloud - optional, upon interest can discuss in office hours/buffer time\n",
    "\n",
    "**Operations**  \n",
    "* Quering databases using Google Big Query, exporting the results \n",
    "\n",
    "**Software requirements** \n",
    "* Python 3\n",
    "* Packages in python: pandas, google-cloud-bigquery, virtualenv (recomended for installing google-cloud packages)\n",
    "    * https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/\n",
    "    * https://googleapis.dev/python/bigquery/latest/index.html \n",
    "\n",
    "**Data**\n",
    "* ghtorrentmysql1906:MySQL1906 (stored on the Google Cloud); it is a full copy of the latest GHtorrent download https://ghtorrent.org/downloads.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Basic concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Go to https://cloud.google.com/, then go to Console, use your Google Account credentials to log-in. This will bring you to the dashboard.\n",
    "\n",
    "Relevant elements on the Dashboard\n",
    "* **Projects** - organise and govern your activities in the Cloud\n",
    "    * Navigate and launch cloud tools (e.g. BigQuery, Storage, Dataprep, etc.)\n",
    "    * Work collaboratively \n",
    "    * API manager \n",
    "    \n",
    "* **Resources** - tools and apps that a project uses in the Cloud, two examples:\n",
    "    * Storage - use to upload large (raw) files for futher analysis or to export query results; these data can be then used to create tables and analyse them in BigQuery\n",
    "    * Datasets in BigQuery - tables ready to be queried \n",
    "    \n",
    "* **Billing** - you are billed for the resources you use https://cloud.google.com/pricing/list, https://cloud.google.com/products/calculator\n",
    "    * Storage - billed for bucket storage \n",
    "    * BigQuery\n",
    "        * for Query processing \n",
    "        * for Table storage \n",
    "    * But there is also smth for free https://cloud.google.com/free/docs/gcp-free-tier \n",
    "       \n",
    "    Eg: Pricing for BigQuery\n",
    "    https://cloud.google.com/bigquery/pricing, but\n",
    "        * 1 TB of querying per month free\n",
    "        * 10 GB of storage each month free\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## 3. Exercises\n",
    "\n",
    "1. In Google Cloud Dashboard: create a new project, can give it any name\n",
    "\n",
    "2. In the Navigation panel: find and click BigQuery (for convenience you can pin tools that you use often)\n",
    "\n",
    "3. Resources: allows to add and keep (pin) data for your queries\n",
    "    * Your own data: you upload a raw csv file to the Storage and then create a table based on the dataset(s)\n",
    "    * Publicly available datasets https://cloud.google.com/bigquery/public-data/\n",
    "        * Those explicitly shared by Google\n",
    "        * Those shared by other organisations/users\n",
    "        * Sample datasets \n",
    "    \n",
    "4. How to pin a dataset to your project\n",
    "    * If you know the dataset's exact name, you can pin it directly: try ADD Data > Pin project > ghtorrentmysql1906 \n",
    "    * Otherwise, you can do it from the webpage of a relevant public dataset. Ex:   \n",
    "    https://console.cloud.google.com/marketplace/details/johnshopkins/covid19_jhu_global_cases\n",
    "    * Once you press 'View Dataset', it will open BigQuery and automatically pin the dataset in your project\n",
    "    * Another very useful feature is to check sample queries of publicly available dataset. If you click: _Run this query_ it automatically opens the query in the BigQuery and pins the dataset for you. \n",
    "    \n",
    "5. We can now repeat the steps I did to generate the GitHub datasets for the previous lecture. \n",
    "\n",
    "I extracted all commits in October 2018\n",
    "\n",
    "https://console.cloud.google.com/bigquery?sq=349652669346:2e2174ccf7514243a07c2a2852cad36a\n",
    "\n",
    "\n",
    "I then extracted repositories and users that had commits in October 2018\n",
    "\n",
    "* https://console.cloud.google.com/bigquery?sq=349652669346:ee4c923ca8f34cb8b52a97b947ceb4ba\n",
    "\n",
    "* https://console.cloud.google.com/bigquery?sq=349652669346:d5c64f3b40474b20a8bb57a98a1cc4e7\n",
    "\n",
    "I saved the results to Google drive and you know what happened next :) \n",
    "\n",
    "\n",
    "6. You can now practice on your own and for ex. see whether our results for October 2018 are representative for all commits in 2018. You can appreciate how fast the merging is! Just watch out for the size of your queries! \n",
    "\n",
    "7. Dashboard is good for getting yourself familiar with Google Cloud tools. If you want to use it for research/work, it makes sense to install a client in your preferred programming language.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Coursera Cloud Platform Courses\n",
    "https://www.coursera.org/specializations/from-data-to-insights-google-cloud-platform \n",
    "\n",
    "Optimising queries\n",
    "https://medium.com/google-cloud/bigquery-optimized-cluster-your-tables-65e2f684594b\n",
    "\n",
    "GitHub queries\n",
    "* https://github.blog/2017-01-19-github-data-ready-for-you-to-explore-with-bigquery/?fbclid=IwAR1E01NhM1kFZE4TM_XC6aDhkWSm2s8oCIsKXA4EcsiixnNdsBo22Kjlwho \n",
    "\n",
    "* https://github.com/fhoffa/analyzing_github/\n",
    "\n",
    "* Note: there are currently several GitHub datasets available on BigQuery\n",
    "    * GHtorrent data: ghtorrentmysql1906 - contains a publicly available GHtorrent dump from June 2019\n",
    "    * GHtorrent data 2: ghtorrent-bq - GHtorrent dumps from 2017 and 2018 https://ghtorrent.org/ \n",
    "    * GitHub Activity data: bigquery-public-data:github_repos. Contains contents from 2.9M public, open source licensed repositories on GitHub. https://console.cloud.google.com/marketplace/details/github/github-repos?filter=solution-type:dataset&q=github&id=46ee22ab-2ca4-4750-81a7-3ee0f0150dcb\n",
    "    * GitHub Archive data: githubarchive Contains data on GitHub events. https://www.gharchive.org/\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
